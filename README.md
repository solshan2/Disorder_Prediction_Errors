## Author List 
Sarah M. Olshan1, Corey J. Richier1, Kyle A. Baacke2, Gregory A. Miller1,3,4, & Wendy Heller1
1Department of Psychology, University of Illinois Urbana-Champaign
2Department of Psychology, University of Wisconsin-Milwaukee
3Department of Psychology, University of California, Los Angeles
4Department of Psychiatry and Biobehavioral Sciences, University of California, Los Angeles

## Data Sources 
UCLA Consortium for Neuropsychiatric Phenomics dataset (Bilder et al., 2018; obtained from https://openneuro.org/datasets/ds000030) 

## Abstract 
Background: Within-disorder heterogeneity complicates mapping neurobiological features to DSM conceptualizations. The present study explored diagnostic errors to better characterize disorder heterogeneity. 
Methods: We conducted classification analyses with the UCLA Phenomics Study database using a support vector classifier to differentiate disorders via whole-brain task-based functional connectivity, predicting that model misclassifications would provide insight about individuals with brain connectivity characteristics shared across disorders. We also explored whether individual differences in symptoms and specific brain networks could account for misclassification rates. 
Results: The classification model performed better than chance (45% accuracy, p = .002) and revealed that misclassification of schizophrenia (SCZ) as bipolar disorder (BD; 36%) and BD as SCZ (39%) was symmetrical. Attention-deficit/hyperactivity disorder (ADHD) was misclassified as BD at the highest rate (45%) and higher than the converse (14%). SCZ and ADHD were misclassified least (SCZ as ADHD 12%; ADHD as SCZ 20%). Considerable variance in misclassification of SCZ as BD (R2 = .93) and BD as SCZ (R2 = .77) could be accounted for by symptoms of both SCZ and BD. Exploratory permutation testing revealed disorder- and network-specific effects, with certain networks improving classification accuracy and others hindering it for specific disorders. 
Conclusion: An approach focused on prediction errors replicated known disorder overlap, producing errors in the expected configuration. Further, it identified clinical and neural features within and across diagnostic categories that contribute to disorder misclassification and may clarify within-disorder heterogeneity. This approach may facilitate neurobiologically informed phenotypic differentiation within diagnostic groups.

## Disorder_Prediction_Errors

Analytic code for "Making the most of errors: Utilizing erroneous predictions generated by machine learning models of neuroimaging data for capturing disorder heterogeneity"

Scripts should be run in the following order: DataPreparation, Analysis1, Analysis2, Analysis 3, and Visuals.

## Data Preparation 

### 0_1_nifty2numpy_parcellation.py

This script takes the raw Nifti file time series as input. It applies an atlas of the user’s choice and saves the output files as numpy arrays. 

### 0_2_connectome_generation.py

This script reads in all available parcellated fMRI data from the UCLA dataset (ds000030) and saves them as functional connectomes.

### 0_3_consolidate_connectomes.py

This script extracts the unique values from each subject’s functional connectivity matrix and appends them all into a singular dataframe for analysis. 

### 0_4_phenotype_consolidation.py

This script extracts information for each subject's responses to the SANS, SAPS, and BipolarII scales. 

## Analysis 1 

### 1_1_prediction_generation.py 

This script fits and runs the support vector classifier model on subjects in the training set and tests on the held out subjects. It also saves the confusion matrix of the results of the classification. 

### 1_2_hyperparameter_evaluation.py 

This script evaluates accuracy as a result of different combinations of hyperparameters for the support vector machine. 

### 1_3_permutation_testing.py 

This script runs the permutations for each of the different cells in the confusion matrix (for each correct classification and misclassification).

## Analysis 2 

### 2_1_individual_differences_regression.Rmd 

This script performs backward stepwise regression and runs regression analysis with the final models for SAPS, SANS, and BipolarII

## Analysis 3 

### 3_1_network_permutation_testing.py 

This script runs permutation testing over the 7 networks from Yeo et al. (2011) for each cell of the confusion matrix (for each correct classification and misclassification). 

### 3_2_feature_importance_t-tests.Rmd 

This script compares the classification/misclassification rates of the models with specific network edges permuted versus randomly permuted collections of edges of the same size.

## Visuals 

### 1_v1_confusion_matrix_visual.py 

Creates Figure 2 in the manuscript: Confusion matrix of observed classification and misclassification rates. 

### 1_v2_permutation_testing_visuals.ipynb 

Creates Figure 3 in the manuscript: The observed classifications and misclassifications (red lines) overlaid on their distributions from permutation testing. 

### 3_v2_effect_size_visuals.ipynb 

Creates Figure 5 in the manuscript: Cohen’s d effect-size values for t-tests of network permutation results.  

### 3_v3_network_permutation_testing_visuals.ipynb

Creates Figure 4: Distributions of classification and misclassification when edges associated with each of the 7 networks from Yeo et al. (2011) were permuted (colored distributions) and randomly selected other sets of edges were permuted for comparison (black distributions). 


